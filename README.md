# CloudInfraAI - AI-Powered OpenStack Infrastructure Monitoring

## ğŸš€ Quick Start

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Place your dataset
cp OpenStack_2k.log_structured.csv data/raw/

# 3. Run complete pipeline
python main.py preprocess
```

**Expected Runtime:** 3-5 minutes on Apple M2 Pro
**Output:** Model-ready PyTorch tensors for Transformer training

---

## ğŸ“ Project Structure

```
CloudInfraAI/
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ ğŸ“„ raw/
â”‚   â”‚   â”œâ”€â”€ OpenStack_2k.log_structured.csv    # Original OpenStack logs
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â””â”€â”€ ğŸ“„ processed/
â”‚       â”œâ”€â”€ processed_dataset_with_labels.csv  # Logs with anomaly labels
â”‚       â”œâ”€â”€ engineered_features.csv            # Extracted features
â”‚       â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/
â”‚   â””â”€â”€ (Future: Jupyter notebooks for EDA)
â”‚
â”œâ”€â”€ ğŸ“‚ saved_models/
â”‚   â””â”€â”€ (Future: Trained PyTorch model files)
â”‚
â”œâ”€â”€ ğŸ“‚ outputs/
â”‚   â”œâ”€â”€ ğŸ“‚ analysis/
â”‚   â”‚   â”œâ”€â”€ analysis_results.json              # Pattern analysis results
â”‚   â”‚   â”œâ”€â”€ analysis_visualizations.png        # Data distribution plots
â”‚   â”‚   â”œâ”€â”€ analysis_summary.txt               # Human-readable insights
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â””â”€â”€ ğŸ“‚ features/
â”‚       â”œâ”€â”€ train_data.pt                      # Training tensors
â”‚       â”œâ”€â”€ val_data.pt                        # Validation tensors
â”‚       â”œâ”€â”€ test_data.pt                       # Test tensors
â”‚       â”œâ”€â”€ encoders.json                      # Categorical encoders
â”‚       â”œâ”€â”€ scalers.json                       # Numerical scalers
â”‚       â”œâ”€â”€ feature_config.json                # Pipeline configuration
â”‚       â”œâ”€â”€ feature_stats.json                 # Feature statistics
â”‚       â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ __init__.py                            # Main package
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ data_processing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_analyzer.py                   # Pattern detection & analysis
â”‚   â”‚   â””â”€â”€ feature_engineer.py                # Feature extraction pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ model/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ architecture.py                    # Transformer model (future)
â”‚   â”‚   â”œâ”€â”€ train.py                          # Training pipeline (future)
â”‚   â”‚   â””â”€â”€ predict.py                        # Inference functions (future)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ dashboard/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ app.py                            # Streamlit dashboard (future)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ alerting/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ slack.py                          # Slack notifications (future)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ (Common utilities - future)
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/
â”‚   â””â”€â”€ run_preprocessing.py                   # Complete preprocessing pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ docs/
â”‚   â”œâ”€â”€ CloudInfraAI_PRD.md                   # Main project requirements
â”‚   â”œâ”€â”€ Data_Processing_PRD.md                # Data processing specifications
â”‚   â””â”€â”€ README.md                             # Comprehensive documentation
â”‚
â”œâ”€â”€ ğŸ“‚ tests/
â”‚   â””â”€â”€ (Unit tests - future)
â”‚
â”œâ”€â”€ ğŸ“‚ configs/
â”‚   â””â”€â”€ (Configuration files - future)
â”‚
â”œâ”€â”€ ğŸ“‚ logs/
â”‚   â””â”€â”€ (Application logs)
â”‚
â”œâ”€â”€ ğŸ“„ main.py                                # Main CLI entry point
â”œâ”€â”€ ğŸ“„ config.py                              # Central configuration
â”œâ”€â”€ ğŸ“„ requirements.txt                       # Python dependencies
â””â”€â”€ ğŸ“„ .gitignore                             # Git ignore rules
```

---

## ğŸ¯ Usage Options

### Option 1: Complete Pipeline (Recommended)
```bash
python main.py preprocess
```
- Runs data analysis + feature engineering
- Full validation and reporting
- Ready for model training

### Option 2: Analysis Only
```bash
python main.py analyze
```
- Data pattern detection
- Anomaly identification
- Visualization generation

### Option 3: Individual Scripts
```bash
# Direct script execution
python scripts/run_preprocessing.py
```

### Option 4: Future Commands
```bash
python main.py train          # Train ML model (coming soon)
python main.py dashboard      # Launch Streamlit app (coming soon)
```

---

## ğŸ“Š Detected Anomaly Patterns

### ğŸ”´ High Priority Anomalies
1. **Memory Spikes**
   - Normal: 512MB baseline
   - Anomaly: â‰¥2560MB (5x spike)
   - Count: ~9 events in dataset

2. **API Latency**
   - Normal: 0.2-0.3 seconds
   - Anomaly: â‰¥0.5 seconds
   - Count: ~10 slow requests

### ğŸŸ¡ Medium Priority Anomalies
3. **HTTP Errors**
   - Normal: 200, 202, 204 status
   - Anomaly: 404, 500+ errors
   - Count: ~15 error responses

4. **System Warnings**
   - Normal: INFO level logs
   - Anomaly: WARNING/ERROR levels
   - Count: ~31 warning events

---

## âš™ï¸ Configuration

The project uses a centralized configuration in `config.py`:

```python
# Key configurations
DataConfig.RAW_DATASET_PATH        # Input dataset location
ModelConfig.SEQUENCE_LENGTH = 50   # Events per sequence
ModelConfig.D_MODEL = 128          # Transformer dimension
SystemConfig.DEVICE               # Auto-detects M2 Pro/GPU/CPU
```

### Hardware Optimization
- **Apple M2 Pro:** Uses MPS acceleration automatically
- **NVIDIA GPU:** Uses CUDA if available
- **CPU Fallback:** Works on any system

---

## ğŸ”§ Development Workflow

### Setting Up Development Environment
```bash
# Clone and setup
git clone <repository>
cd CloudInfraAI
pip install -r requirements.txt

# Place your dataset
cp your_dataset.csv data/raw/OpenStack_2k.log_structured.csv

# Run analysis
python main.py analyze
```

### Adding New Features
1. **Data Processing:** Add modules to `src/data_processing/`
2. **Models:** Add architectures to `src/model/`
3. **Dashboard:** Add components to `src/dashboard/`
4. **Utilities:** Add helpers to `src/utils/`

### Project Conventions
- **Import Structure:** Use relative imports within packages
- **Configuration:** Central config in `config.py`
- **Logging:** Structured logging to `logs/` directory
- **Documentation:** Comprehensive docstrings and comments

---

## ğŸ“ˆ Expected Results

### Processing Metrics (M2 Pro)
- **Execution Time:** 3-5 minutes
- **Memory Usage:** <3GB RAM
- **Sequences Generated:** 50-100 from 2k logs
- **Feature Count:** 25+ per event
- **Anomaly Ratio:** ~15%

### Quality Validation
```
âœ… Data loaded: 2,001 log entries
âœ… Patterns detected: Memory, API, lifecycle, health
âœ… Features extracted: Numerical, categorical, binary
âœ… Sequences created: 5-minute windows
âœ… Labels generated: Binary anomaly classification
âœ… Artifacts saved: Encoders, scalers, configs
```

---

## ğŸš¨ Troubleshooting

### Common Issues

#### Dataset Not Found
```bash
Error: Dataset not found at data/raw/OpenStack_2k.log_structured.csv
```
**Solution:** Place dataset in correct location
```bash
mkdir -p data/raw
cp OpenStack_2k.log_structured.csv data/raw/
```

#### PyTorch MPS Errors (M2 Pro)
```bash
# Force CPU if MPS issues
export PYTORCH_ENABLE_MPS_FALLBACK=1
python main.py preprocess
```

#### Import Errors
```bash
# Ensure you're in project root
cd CloudInfraAI
python main.py preprocess
```

#### Memory Issues
```python
# Edit config.py for lower memory usage
ModelConfig.SEQUENCE_LENGTH = 30    # Reduce from 50
ModelConfig.BATCH_SIZE = 16         # Reduce from 32
```

---

## ğŸ”® Future Development Phases

### Phase 2: Model Training
- Transformer architecture implementation
- Training pipeline with M2 Pro optimization
- Model evaluation and validation

### Phase 3: Real-time Dashboard
- Streamlit application
- Live monitoring interface
- Interactive visualizations

### Phase 4: Production Deployment
- Slack alert integration
- Docker containerization
- Kubernetes deployment ready

---

## ğŸ“š Documentation

- **Main PRD:** `docs/CloudInfraAI_PRD.md` - Project requirements
- **Data PRD:** `docs/Data_Processing_PRD.md` - Technical specifications
- **API Docs:** Generated from code docstrings
- **Notebooks:** Analysis and exploration in `notebooks/`

---

## ğŸ¤ Contributing

### Development Setup
```bash
# Setup development environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt

# Run tests (when implemented)
python -m pytest tests/

# Format code
black src/ scripts/ main.py config.py
```

### Code Standards
- **Python 3.9+** with type hints
- **PEP 8** formatting with black
- **Comprehensive docstrings** for all functions
- **Unit tests** for core functionality

---

## ğŸ“„ License

This project is part of the CloudInfraAI capstone project. See project documentation for licensing details.

---

**Ready to detect OpenStack infrastructure anomalies with AI! ğŸš€**

Need help? Run `python main.py --help` for command options.